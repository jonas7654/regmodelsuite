---
title: "Ridge"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Ridge}
=======
title: "Ridge Regression with Custom Function"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Ridge Regression with Custom Function}
>>>>>>> 30cd6c235c07828bb55b9a06058fbf081a3e9612
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

<<<<<<< HEAD
This vignette demonstrates how to estimate a Ridge regression model using the `regmodelsuite` package. Ridge is a type of linear regression that includes a penalty to shrink some coefficients.

First we are going to create some example Data where the number of predictors
is greater than the number of observations p >> n

```{r}
library(regmodelsuite)

set.seed(123)  # For reproducibility

# Parameters
n <- 200  # Number of observations
p <- 600  # Number of predictors

# Generate predictor matrix (X) with normal distributed values
X <- matrix(rnorm(n * p), nrow = n, ncol = p)

# Create a true coefficient vector
beta_true <- rnorm(p)

# zero out some coefficients
beta_true[abs(beta_true) < 0.5] <- 0

# Generate response variable (y) as a linear combination of predictors + noise
y <- X %*% beta_true + rnorm(n)

# Convert to data frame
df <- data.frame(X)
df$y <- y


# Split the dataset into a training and test set (50/50)
Indexes <- sample(1:(nrow(df) * 0.5))

training_set <- df[Indexes , ]
test_set <- df[-Indexes , ]
```
To estimate a ridge model the user has to supply a formula into the regmodel
function.


```{r}
# seed for reproducebillity
set.seed(2302)
model_formula <- y ~ .
ridgeCV <- regmodel(model_formula, data = training_set, model = "ridge", cv = T)

min_lambda <- ridgeCV$min_lambda

print(ridgeCV)


```
The "ridge_fit" object contains information about the cross validation process. To use the estimated lambda for the final model we can use \code{regmodel} again

```{r}
ridge_fit <- regmodel(model_formula,
                      data = training_set,
                      model = "ridge",
                      lambda = min_lambda)

print(ridge_fit)
```
In this case three variables were selected by the ridge model

Predictions can be done by using the \code{predict()} function.
Just calling predict on a ridge object will use the training data set for 
predictions. By specifying \code{newdata}, the estimated model will be applied to 
the new data.

```{r}
pred_insample <- predict(ridge_fit)
print(pred_insample)

# Now use the test set
pred_outofsample <- predict(ridge_fit, newdata = test_set)
```

We can visualize the predictions using ggplot2
```{r}

```

This vignette demonstrates how to do ridge regression using the `regmodelsuite` package.

```{r setup}
library(regmodelsuite)
```

## Example data

```{r}
set.seed(21)
n <- 100
d <- 10
testlambda <- 0.1

#data X independent and equally distributed on [0,1]
X <- matrix(runif(n * d), n, d)

#real values of beta
beta <- runif(d, min = -1, max = 1) 

#measured y with normally distributed measurement error N(0,0.3^2)
y <- X %*% real_ridge + rnorm(n, mean = 0, sd = 0.3)

#datafram
df <- data.frame(X)
df$y <- y
```

## Basic usage of the ridge function

```{r}
ridge <- regmodel(data=df, model = "ridge", lambda = testlambda)
print(ridge)
```

You can also plot your ridgeobject:

```{r}
plot(ridge)
```

