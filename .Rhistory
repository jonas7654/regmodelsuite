library(glmnet)
coef(glmnet(X, y, intercept = F, lambda = 0))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
coef(glmnet(X, y, intercept = F, lambda = 0.1))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0.1)
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0.1)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 0.1))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0.1)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 0.1))
coef(glmnet(X, y, intercept = F, lambda = 1))
coef(glmnet(X, y, intercept = F, lambda = 1))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 1))
coef(glmnet(X, y, intercept = F, lambda = 1, intercept = F))
coef(glmnet(X, y, intercept = F, lambda = 1))
true_beta
coef(glmnet(X, y, intercept = F, lambda = 0))
true_beta
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)$coefficients
devtools::load_all()
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)$coefficients
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 0)
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)
coef(glmnet(X, y, intercept = F, lambda = 1, alpha = 0))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)
coef(glmnet(X, y, intercept = F, lambda = 1, alpha = 0))
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)
coef(glmnet(X, y, intercept = F, lambda = 1, alpha = 0))
devtools::load_all()
# linear model
sum(abs(lm(y ~ x1 + x2 + x3 + x4 + x5 + 0, data = dataframe)$coefficients - true_beta))
# lasso
sum(abs(regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" ,lambda = 0) - true_beta))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 0))
true_beta
# ridge
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "ridge" , lambda = 1)
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)
#' Wrapper Function for the regmodelsuit package.
#'
#' @param formula A formula object which specifies the model
#' @param data A data frame which contains the corresponding variables
#' @param model Specifies the model to be estimated.
#'   c("ridge","lasso","forward","backward","LAR")
#' @param lambda penalty parameter for ridge and lasso estimation. If cv = TRUE
#'   lambda will be ignored all of them are tested to find the optimal lambda
#'   with regard to the chosen regmodel
#' @param model Logical value which specifies if cross validation for lambda
#'   should be used
#'  @param ... Additional parameter for the model. Further information see:
#'    \link[regmodelsuite]{lasso}
#'
#' @return Model List
#' @export
# TODO
# Add option to remove or include intercept ?
regmodel <- function(formula = NULL, data = NULL, model = NULL, lambda = 0,
cv = FALSE, intercept = FALSE , ...) {
# Input checks
stopifnot("missing formula object" =
!is.null(formula) || (inherits(formula, "formula")
)
)
stopifnot("please specify a model \n
ridge,
lasso,
forward,
backward,
LAR            " =
(is.character(model) && (model %in% c("ridge",
"lasso",
"forward",
"backward",
"LAR")
)
)
)
stopifnot("lambda must be a positiv number" =
(is.numeric(lambda) && lambda >= 0)
)
stopifnot("cv must be a boolean of length one" =
(is.logical(cv) && length(cv) == 1)
)
stopifnot("data must be NULL or a data frame" =
is.null(data) || is.data.frame(data)
)
stopifnot("Intercept must be TRUE or FALSE" =
is.logical(intercept)
)
########################################################################
# Extract data from parent environments up until the globalenv
if (is.null(data)) {
var_names <- all.vars(formula)
data <- sapply(var_names, function(names) {
recursive_data_search(names, parent.frame())
})
data <- as.data.frame(data)
# Check that all variables were collected
if (ncol(data) != length(var_names)) {
stop("Couldn't find all variables")
}
names(data) <- var_names
}
# Intercept handling
if (!intercept) {
# remove the intercept (base case)
t <- terms(formula, data = data)
formula <- update.formula(formula(t), ~ . + 0)
}
# Create model frame
mf <- model.frame(formula, data = data)
X <- model.matrix(formula, data = data)
y <- model.response(mf)
# Init
results <- list()
# extract column names
var_names_x <- dimnames(X)[[2]]
names(X) <- var_names_x
# Ridge call
if (model == "ridge") {
results <- ridge(X, y, lambda)
}
# Least angle regression call
if (model == "LAR") {
fit <- least_angle_regression(X, y)
names(fit$coefficients) <- var_names_x
results <- fit
}
# Lasso regression call
if (model == "lasso") {
if (cv) {
}
else {
results <- lasso(X, y, lambda)
}
}
return(results)
}
ambda
# lasso
sum(abs(regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" ,lambda = 0) - true_beta))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)
coef(glmnet(X, y, intercept = F, lambda = 0))
true_beta
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
devtools::load_all()
rm(list = ls())
devtools::load_all()
### Test with synthetic data ###
n <- 1000
p <- 5
true_beta <- runif(p , min = 0, 10)
X <- matrix(rnorm(n * p), n, p)
dimnames(X)[[2]] <- paste0("x",1:p)
y <- X %*% true_beta + rnorm(n)
dataframe <- data.frame(y = y, X)
# linear model
sum(abs(lm(y ~ x1 + x2 + x3 + x4 + x5 + 0, data = dataframe)$coefficients - true_beta))
# lasso
sum(abs(regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" ,lambda = 0) - true_beta))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 0))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
# lasso
sum(abs(regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" ,lambda = 0) - true_beta))
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 1)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 0))
true_beta
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)$coefficients
coef(glmnet(X, y, intercept = F, lambda = 0))
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)$coefficients
devtools::load_all()
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)$coefficients
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
#' Calculate the Lasso estimates
#'
#' @param X data frame containing the covariates
#' @param Y response vector
#' @param lambda penalty parameter ($\lambda > 0$)
#' @param tol tolerance level for convergence (default = 1e-5)
#'
#' @return list ..... TODO
lasso <- function(X, y, lambda,  tol = 1e-07, verbose = F) {
if (lambda == 0) {
OLS <- lm.fit(X, y)$coefficients # solve(t(X) %*% X, t(X) %*% y)
if (ncol(X) >= nrow(X)) {
warning("The matrix X suffers from multicollinearity")
}
return(list(coefficients = coef(OLS)))
}
n <- nrow(X)
p <- ncol(X)
# Init
X_scaled <- scale(X, scale = F)
beta <- double(p)
max_abs_beta_diff <- Inf
mean_X_scaled_squared <- colMeans(X_scaled^2)
m <- 0L
while(max_abs_beta_diff > tol) {
# Only for debugging
if(verbose) {
cat("Iteration:", m, "\n")
cat("beta_diff:", max_abs_beta_diff, "\n")
}
beta_old <- beta
for (j in 1:p) {
# 1
r <- y - X_scaled[ , -j] %*% beta[-j]
# 2
beta_j_tilde <- mean(X_scaled[ , j] * r)
# 3
beta_j_next <- ifelse(j == 1, beta_j_tilde,
(1 / mean_X_scaled_squared[j]) *
sign(beta_j_tilde) *
max(0, (abs(beta_j_tilde) - (lambda/2)))
)
beta[j] <- beta_j_next
}
max_abs_beta_diff <- max(abs(beta - beta_old))
m <- m + 1
}
# Output section
lasso_obj <- list(coefficients = round(beta, 6),
iterations = m,
lambda = lambda)
class(lasso_obj) <- "lasso"
return(lasso_obj)
}
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
devtools::load_all()
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
model_formula <- formula(y ~ x1 + x2 + x3 + x4 + x5)
# linear model
lm(model_formula)
# linear model
lm(model_formula, data = dataframe)
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# linear model
lm(model_formula, data = dataframe)
true_beta
devtools::load_all()
# least angle
regmodel(model_formula, data = dataframe, model "LAR")
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
#' Calculate the LARS path
#'
#' @param X data frame containing the covariates
#' @param Y response vector
#'
#' @return list ..... TODO
### TODO ####
# plot(...) for plotting L1-arc length
least_angle_regression <- function(X, y, verbose = F) {
n <- nrow(X)
p <- ncol(X)
max_iter <- min(n - 1, p)
# scale variables
X_scaled <- X # scale(X)
y_demeaned <- y #scale(y, scale = F)
# Init
r <- y_demeaned
beta <- double(p)
active_variables <- logical(p)
coefficient_matrix <- matrix(0, max_iter, p)
for (i in 1:max_iter) {
# Calculate correlation
C_j <- t(X) %*% r
j_star <- which.max(abs((C_j[!active_variables , ])))
C_max <- C_j[j_star]
active_variables[j_star] <- TRUE
A <- X_scaled[ , active_variables, drop = FALSE]
#
A_tilde <- A * sign(C_j[active_variables , ])
A_tilde_A_inverse <- solve(t(A_tilde) %*% A_tilde)
ones <- matrix(1, nrow(A_tilde_A_inverse), 1)
ones_transposed <- t(ones)
w <- ones_transposed %*% A_tilde_A_inverse %*% ones
sqrt_w <- as.double(sqrt(w))
u <- (A_tilde %*% A_tilde_A_inverse %*% matrix(1, ncol(A_tilde %*% A_tilde_A_inverse) , 1)) / sqrt_w
# calculate step size
B <- t(X_scaled) %*% u
if (i == max_iter) {
alpha <- C_max * sqrt_w
}
else {
alpha_neg <- (C_max - C_j[!active_variables]) / ((1 / sqrt_w) - B[!active_variables, ])
alpha_pos <- (C_max + C_j[!active_variables]) / ((1 / sqrt_w) + B[!active_variables, ])
alpha <- min(c(alpha_neg[alpha_neg > 0], alpha_pos[alpha_pos > 0]), na.rm = TRUE)
}
# update beta and r
delta_step <- sign(C_j[active_variables, ]) * solve(t(A) %*% A, t(A) %*% u)
beta[active_variables] <- beta[active_variables] + alpha * delta_step
r <- r - alpha * u
#r <- r - A %*% delta_step
############################################################################
# Verbose option
if (verbose) {
cat("Iteration:", i, "\n")
cat("Active Variables:", which(active_variables), "\n")
cat("delta :", delta_step, "\n")
cat("alpha :", alpha, "\n")
cat("Coefficients:", beta, "\n")
cat("\n")
}
# update output data
coefficient_matrix[i, ] <- beta
}
# Calculate arc length
arg_length <- apply(coefficient_matrix, 1, function(x) {sum(abs(x))})
# Calculate R-Squared for each model
r2 <- apply(coefficient_matrix, 1, function(beta) {calculate_R2(y, X %*% beta)}
)
output_list <- list(coefficients = coefficient_matrix,
l1_arc_length = arg_length,
R2 = r2)
# Modify S3 class
class(output_list) <- "LAR"
return (output_list)
}
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lasso")$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lasso", lamvbda = 5)$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lasso", lambda = 5)$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lar", lamvbda =)$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "LAR", lamvbda =)$coefficients
names(dataframe)
dimnames(dataframe)
dimnames(dataframe)[[2]]
dimnames(dataframe)[[1]]
dimnames(dataframe)[[3]]
dimnames(dataframe)[2]
dimnames(dataframe)[[2]]
n <- 1000
p <- 5
X <- matrix(rnorm(n*p), n, p)
true_beta <- 1:p
y <- X %*% true_beta + rnorm(n)
lm(y ~ X + 0)
least_angle_regression(X, y)
coef(lars(X, y, type = "lar"))
lars(X, y, type = "lar")
coef(lars(X, y, type = "lar"))
### Test with synthetic data ###
n <- 1000
p <- 5
true_beta <- runif(p , min = 0, 10)
X <- matrix(rnorm(n * p), n, p)
dimnames(X)[[2]] <- paste0("x",1:p)
y <- X %*% true_beta + rnorm(n)
model_formula <- formula(y ~ x1 + x2 + x3 + x4 + x5)
dataframe <- data.frame(y = y, X)
# linear model
lm(model_formula, data = dataframe) #With intercept
# lasso with lambda = 0 => OLS
regmodel(model_formula, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR", lamvbda =)$coefficients
coef(lars(X, y, type = "lar"))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
p <- 10
true_beta <- runif(p , min = 0, 10)
X <- matrix(rnorm(n * p), n, p)
dimnames(X)[[2]] <- paste0("x",1:p)
y <- X %*% true_beta + rnorm(n)
model_formula <- formula(y ~ x1 + x2 + x3 + x4 + x5)
dataframe <- data.frame(y = y, X)
# linear model
lm(model_formula, data = dataframe) #With intercept
# lasso with lambda = 0 => OLS
regmodel(model_formula, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
coef(lars(X, y, type = "lar"))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
coef(lars(X, y, type = "lar"))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
# least angle
least_angle_regression(X, y, T)
#' Calculate the LARS path
#'
#' @param X data frame containing the covariates
#' @param Y response vector
#'
#' @return list ..... TODO
### TODO ####
# plot(...) for plotting L1-arc length
least_angle_regression <- function(X, y, verbose = F) {
n <- nrow(X)
p <- ncol(X)
max_iter <- min(n - 1, p)
# scale variables
X_scaled <- scale(X)
y_demeaned <- scale(y, scale = F)
# Init
r <- y_demeaned
beta <- double(p)
active_variables <- logical(p)
coefficient_matrix <- matrix(0, max_iter, p)
for (i in 1:max_iter) {
# Calculate correlation
C_j <- t(X) %*% r
j_star <- which.max(abs((C_j[!active_variables , ])))
C_max <- C_j[j_star]
active_variables[j_star] <- TRUE
A <- X_scaled[ , active_variables, drop = FALSE]
#
A_tilde <- A * sign(C_j[active_variables , ])
A_tilde_A_inverse <- solve(t(A_tilde) %*% A_tilde)
ones <- matrix(1, nrow(A_tilde_A_inverse), 1)
ones_transposed <- t(ones)
w <- ones_transposed %*% A_tilde_A_inverse %*% ones
sqrt_w <- as.double(sqrt(w))
u <- (A_tilde %*% A_tilde_A_inverse %*% matrix(1, ncol(A_tilde %*% A_tilde_A_inverse) , 1)) / sqrt_w
# calculate step size
B <- t(X_scaled) %*% u
if (i == max_iter) {
alpha <- C_max * sqrt_w
}
else {
alpha_neg <- (C_max - C_j[!active_variables]) / ((1 / sqrt_w) - B[!active_variables, ])
alpha_pos <- (C_max + C_j[!active_variables]) / ((1 / sqrt_w) + B[!active_variables, ])
alpha <- min(c(alpha_neg[alpha_neg > 0], alpha_pos[alpha_pos > 0]), na.rm = TRUE)
}
# update beta and r
delta_step <- sign(C_j[active_variables, ]) * solve(t(A) %*% A, t(A) %*% u)
beta[active_variables] <- beta[active_variables] + alpha * delta_step
r <- r - alpha * u
#r <- r - A %*% delta_step
############################################################################
# Verbose option
if (verbose) {
cat("Iteration:", i, "\n")
cat("Active Variables:", which(active_variables), "\n")
cat("delta :", delta_step, "\n")
cat("alpha :", alpha, "\n")
cat("Coefficients:", beta, "\n")
cat("\n")
}
# update output data
coefficient_matrix[i, ] <- beta
}
# Calculate arc length
arg_length <- apply(coefficient_matrix, 1, function(x) {sum(abs(x))})
# Calculate R-Squared for each model
r2 <- apply(coefficient_matrix, 1, function(beta) {calculate_R2(y, X %*% beta)}
)
output_list <- list(coefficients = coefficient_matrix,
l1_arc_length = arg_length,
R2 = r2)
# Modify S3 class
class(output_list) <- "LAR"
return (output_list)
}
# least angle
least_angle_regression(X, y, T)
devtools::load_all()
# least angle
least_angle_regression(X, y, T)
least_angle_regression(X, y)
X <- matrix(rnorm(n*p), n, p)
true_beta <- 1:p
y <- X %*% true_beta + rnorm(n)
lm(y ~ X + 0)
least_angle_regression(X, y)
n <- 1000
p <- 5
X <- matrix(rnorm(n*p), n, p)
true_beta <- 1:p
y <- X %*% true_beta + rnorm(n)
lm(y ~ X + 0)
least_angle_regression(X, y)
coef(lars(X, y, type = "lar"))
