# 3
beta_j_next <- ifelse(j == 1, beta_j_tilde,
(1 / mean_X_scaled_squared[j]) *
sign(beta_j_tilde) *
max(0, (abs(beta_j_tilde) - (lambda/2)))
)
beta[j] <- beta_j_next
}
max_abs_beta_diff <- max(abs(beta - beta_old))
m <- m + 1
}
# Output section
lasso_obj <- list(coefficients = round(beta, 6),
iterations = m,
lambda = lambda)
class(lasso_obj) <- "lasso"
return(lasso_obj)
}
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
devtools::load_all()
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
model_formula <- formula(y ~ x1 + x2 + x3 + x4 + x5)
# linear model
lm(model_formula)
# linear model
lm(model_formula, data = dataframe)
# lasso
regmodel(y ~ x1 + x2 + x3 + x4 + x5, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# linear model
lm(model_formula, data = dataframe)
true_beta
devtools::load_all()
# least angle
regmodel(model_formula, data = dataframe, model "LAR")
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
#' Calculate the LARS path
#'
#' @param X data frame containing the covariates
#' @param Y response vector
#'
#' @return list ..... TODO
### TODO ####
# plot(...) for plotting L1-arc length
least_angle_regression <- function(X, y, verbose = F) {
n <- nrow(X)
p <- ncol(X)
max_iter <- min(n - 1, p)
# scale variables
X_scaled <- X # scale(X)
y_demeaned <- y #scale(y, scale = F)
# Init
r <- y_demeaned
beta <- double(p)
active_variables <- logical(p)
coefficient_matrix <- matrix(0, max_iter, p)
for (i in 1:max_iter) {
# Calculate correlation
C_j <- t(X) %*% r
j_star <- which.max(abs((C_j[!active_variables , ])))
C_max <- C_j[j_star]
active_variables[j_star] <- TRUE
A <- X_scaled[ , active_variables, drop = FALSE]
#
A_tilde <- A * sign(C_j[active_variables , ])
A_tilde_A_inverse <- solve(t(A_tilde) %*% A_tilde)
ones <- matrix(1, nrow(A_tilde_A_inverse), 1)
ones_transposed <- t(ones)
w <- ones_transposed %*% A_tilde_A_inverse %*% ones
sqrt_w <- as.double(sqrt(w))
u <- (A_tilde %*% A_tilde_A_inverse %*% matrix(1, ncol(A_tilde %*% A_tilde_A_inverse) , 1)) / sqrt_w
# calculate step size
B <- t(X_scaled) %*% u
if (i == max_iter) {
alpha <- C_max * sqrt_w
}
else {
alpha_neg <- (C_max - C_j[!active_variables]) / ((1 / sqrt_w) - B[!active_variables, ])
alpha_pos <- (C_max + C_j[!active_variables]) / ((1 / sqrt_w) + B[!active_variables, ])
alpha <- min(c(alpha_neg[alpha_neg > 0], alpha_pos[alpha_pos > 0]), na.rm = TRUE)
}
# update beta and r
delta_step <- sign(C_j[active_variables, ]) * solve(t(A) %*% A, t(A) %*% u)
beta[active_variables] <- beta[active_variables] + alpha * delta_step
r <- r - alpha * u
#r <- r - A %*% delta_step
############################################################################
# Verbose option
if (verbose) {
cat("Iteration:", i, "\n")
cat("Active Variables:", which(active_variables), "\n")
cat("delta :", delta_step, "\n")
cat("alpha :", alpha, "\n")
cat("Coefficients:", beta, "\n")
cat("\n")
}
# update output data
coefficient_matrix[i, ] <- beta
}
# Calculate arc length
arg_length <- apply(coefficient_matrix, 1, function(x) {sum(abs(x))})
# Calculate R-Squared for each model
r2 <- apply(coefficient_matrix, 1, function(beta) {calculate_R2(y, X %*% beta)}
)
output_list <- list(coefficients = coefficient_matrix,
l1_arc_length = arg_length,
R2 = r2)
# Modify S3 class
class(output_list) <- "LAR"
return (output_list)
}
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lasso")$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lasso", lamvbda = 5)$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lasso", lambda = 5)$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "lar", lamvbda =)$coefficients
# least angle
regmodel(model_formula, data = dataframe, model = "LAR", lamvbda =)$coefficients
names(dataframe)
dimnames(dataframe)
dimnames(dataframe)[[2]]
dimnames(dataframe)[[1]]
dimnames(dataframe)[[3]]
dimnames(dataframe)[2]
dimnames(dataframe)[[2]]
n <- 1000
p <- 5
X <- matrix(rnorm(n*p), n, p)
true_beta <- 1:p
y <- X %*% true_beta + rnorm(n)
lm(y ~ X + 0)
least_angle_regression(X, y)
coef(lars(X, y, type = "lar"))
lars(X, y, type = "lar")
coef(lars(X, y, type = "lar"))
### Test with synthetic data ###
n <- 1000
p <- 5
true_beta <- runif(p , min = 0, 10)
X <- matrix(rnorm(n * p), n, p)
dimnames(X)[[2]] <- paste0("x",1:p)
y <- X %*% true_beta + rnorm(n)
model_formula <- formula(y ~ x1 + x2 + x3 + x4 + x5)
dataframe <- data.frame(y = y, X)
# linear model
lm(model_formula, data = dataframe) #With intercept
# lasso with lambda = 0 => OLS
regmodel(model_formula, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR", lamvbda =)$coefficients
coef(lars(X, y, type = "lar"))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
p <- 10
true_beta <- runif(p , min = 0, 10)
X <- matrix(rnorm(n * p), n, p)
dimnames(X)[[2]] <- paste0("x",1:p)
y <- X %*% true_beta + rnorm(n)
model_formula <- formula(y ~ x1 + x2 + x3 + x4 + x5)
dataframe <- data.frame(y = y, X)
# linear model
lm(model_formula, data = dataframe) #With intercept
# lasso with lambda = 0 => OLS
regmodel(model_formula, data = dataframe, model = "lasso" , lambda = 0)
coef(glmnet(X, y, intercept = F, lambda = 0))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
coef(lars(X, y, type = "lar"))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
coef(lars(X, y, type = "lar"))
# least angle
regmodel(model_formula, data = dataframe, model = "LAR")$coefficients
# least angle
least_angle_regression(X, y, T)
#' Calculate the LARS path
#'
#' @param X data frame containing the covariates
#' @param Y response vector
#'
#' @return list ..... TODO
### TODO ####
# plot(...) for plotting L1-arc length
least_angle_regression <- function(X, y, verbose = F) {
n <- nrow(X)
p <- ncol(X)
max_iter <- min(n - 1, p)
# scale variables
X_scaled <- scale(X)
y_demeaned <- scale(y, scale = F)
# Init
r <- y_demeaned
beta <- double(p)
active_variables <- logical(p)
coefficient_matrix <- matrix(0, max_iter, p)
for (i in 1:max_iter) {
# Calculate correlation
C_j <- t(X) %*% r
j_star <- which.max(abs((C_j[!active_variables , ])))
C_max <- C_j[j_star]
active_variables[j_star] <- TRUE
A <- X_scaled[ , active_variables, drop = FALSE]
#
A_tilde <- A * sign(C_j[active_variables , ])
A_tilde_A_inverse <- solve(t(A_tilde) %*% A_tilde)
ones <- matrix(1, nrow(A_tilde_A_inverse), 1)
ones_transposed <- t(ones)
w <- ones_transposed %*% A_tilde_A_inverse %*% ones
sqrt_w <- as.double(sqrt(w))
u <- (A_tilde %*% A_tilde_A_inverse %*% matrix(1, ncol(A_tilde %*% A_tilde_A_inverse) , 1)) / sqrt_w
# calculate step size
B <- t(X_scaled) %*% u
if (i == max_iter) {
alpha <- C_max * sqrt_w
}
else {
alpha_neg <- (C_max - C_j[!active_variables]) / ((1 / sqrt_w) - B[!active_variables, ])
alpha_pos <- (C_max + C_j[!active_variables]) / ((1 / sqrt_w) + B[!active_variables, ])
alpha <- min(c(alpha_neg[alpha_neg > 0], alpha_pos[alpha_pos > 0]), na.rm = TRUE)
}
# update beta and r
delta_step <- sign(C_j[active_variables, ]) * solve(t(A) %*% A, t(A) %*% u)
beta[active_variables] <- beta[active_variables] + alpha * delta_step
r <- r - alpha * u
#r <- r - A %*% delta_step
############################################################################
# Verbose option
if (verbose) {
cat("Iteration:", i, "\n")
cat("Active Variables:", which(active_variables), "\n")
cat("delta :", delta_step, "\n")
cat("alpha :", alpha, "\n")
cat("Coefficients:", beta, "\n")
cat("\n")
}
# update output data
coefficient_matrix[i, ] <- beta
}
# Calculate arc length
arg_length <- apply(coefficient_matrix, 1, function(x) {sum(abs(x))})
# Calculate R-Squared for each model
r2 <- apply(coefficient_matrix, 1, function(beta) {calculate_R2(y, X %*% beta)}
)
output_list <- list(coefficients = coefficient_matrix,
l1_arc_length = arg_length,
R2 = r2)
# Modify S3 class
class(output_list) <- "LAR"
return (output_list)
}
# least angle
least_angle_regression(X, y, T)
devtools::load_all()
# least angle
least_angle_regression(X, y, T)
least_angle_regression(X, y)
X <- matrix(rnorm(n*p), n, p)
true_beta <- 1:p
y <- X %*% true_beta + rnorm(n)
lm(y ~ X + 0)
least_angle_regression(X, y)
n <- 1000
p <- 5
X <- matrix(rnorm(n*p), n, p)
true_beta <- 1:p
y <- X %*% true_beta + rnorm(n)
lm(y ~ X + 0)
least_angle_regression(X, y)
coef(lars(X, y, type = "lar"))
devtools::load_all()
devtools::load_all()
y <- 1:3
x <- 1:4
regmodel(y ~ x, model = "ridge", lambda = 0)
y <- 1:3
x <- dataframe(x1 = 1:3, x2 = 1:3)
regmodel(y ~ x, model = "ridge", lambda = 0)
x <- data.frame(x1 = 1:3, x2 = 1:3)
x
y <- 1:3
x <- data.frame(x1 = 1:3, x2 = 1:3)
regmodel(y ~ x, model = "ridge", lambda = 0)
y <- 1:3
x <- data.frame(x1 = 1:3, x2 = 1:3)
regmodel(y ~ x, model = "ridge", lambda = 0)
devtools::load_all()
y <- 1:3
x <- data.frame(x1 = 1:3, x2 = 1:3)
regmodel(y ~ x, model = "ridge", lambda = 0)
data()
data
as.matrix(data)
View(print.ridge())
View(print.ridge)
x
y
fit <- regmodel(y ~ x, model = "ridge", lambda = 0.1)
fit <- regmodel(y ~ x, model = "ridge", lambda = 0.1)
y <- 1:3
x <- c(2,1,10)
regmodel(y ~ x, model = "ridge", lambda = 0.1)
devtools::load_all()
y <- 1:3
x <- c(2,1,10)
regmodel(y ~ x, model = "ridge", lambda = 0.1)
?backward_selection
usethis::use_r("predict.LAR.R")
# Set the seed for reproducibility
set.seed(123)
# Define the number of observations and predictors
n <- 100  # number of observations
p <- 10   # number of predictors
# Generate a random design matrix X (normally distributed)
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
# Generate a true beta vector
beta_true <- c(2, -1.5, 0, 3, 0, -2, 1, 0, 0, 1.5)
# Generate a response variable with some noise
y <- X %*% beta_true + rnorm(n)
# Add some multicollinearity (make some predictors correlated)
X[, 2] <- X[, 1] + rnorm(n) * 0.01  # Make X2 highly correlated with X1
X[, 4] <- X[, 3] + rnorm(n) * 0.01  # Make X4 highly correlated with X3
df <- data.frame(y, X)
X
fit <- regmodel(y ~ ., data = df, model = "ridge" , lambda = 0.5)
fit
class(fit)
print.ridge(fit)
fit
print.ridge(fit)
class(fit)
print.ridge(fit)
# Define the number of observations and predictors
n <- 10000  # number of observations
p <- 10   # number of predictors
# Generate a random design matrix X (normally distributed)
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
# Generate a true beta vector
beta_true <- c(2, -1.5, 0, 3, 0, -2, 1, 0, 0, 1.5)
# Generate a response variable with some noise
y <- X %*% beta_true + rnorm(n)
df <- data.frame(y, X)
fit <- regmodel(y ~ ., data = df, model = "ridge" , lambda = 0.5)
print.ridge(fit)
predict.ridge(fit)
y
min(y)
max(y)
y
round(y,4)
y
round(y,4)
round(predict.ridge(fit), 5)
round(y , 5)
min(y)
max(y)
round(predict.ridge(fit), 5)
min(round(predict.ridge(fit), 5))
max(round(predict.ridge(fit), 5))
s <- sample(1:nrow(X))
s
# Generate a random design matrix X (normally distributed)
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
s <- sample(1:nrow(X))
X <- X[s , ]
X_insample <- X[1:(nrow(X)/ 2)]
X_outofsample <- X[(nrow(X) / 2) : nrow(X)]
# Generate a response variable with some noise
y <- X_insample %*% beta_true + rnorm(nrow(X_insample))
s <- sample(1:nrow(X))
X <- X[s , ]
X_insample <- X[1:(nrow(X)/ 2) , ]
X_outofsample <- X[(nrow(X) / 2) : nrow(X), ]
# Generate a true beta vector
beta_true <- c(2, -1.5, 0, 3, 0, -2, 1, 0, 0, 1.5)
# Generate a response variable with some noise
y <- X_insample %*% beta_true + rnorm(nrow(X_insample))
df <- data.frame(y, X_insample)
fit <- regmodel(y ~ ., data = df, model = "ridge" , lambda = 0.5)
print.ridge(fit)
round(predict.ridge(fit, X_outofsample), 5)
devtools::load_all()
# Generate a random design matrix X (normally distributed)
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
s <- sample(1:nrow(X))
X <- X[s , ]
X_insample <- X[1:(nrow(X)/ 2) , ]
X_outofsample <- X[(nrow(X) / 2) : nrow(X), ]
# Generate a true beta vector
beta_true <- c(2, -1.5, 0, 3, 0, -2, 1, 0, 0, 1.5)
# Generate a response variable with some noise
y <- X_insample %*% beta_true + rnorm(nrow(X_insample))
df <- data.frame(y, X_insample)
fit <- regmodel(y ~ ., data = df, model = "ridge" , lambda = 0.5)
print.ridge(fit)
round(predict.ridge(fit, X_outofsample), 5)
round(predict.ridge(fit, as.data.frame(X_outofsample)), 5)
pred <- round(predict.ridge(fit, as.data.frame(X_outofsample)), 5)
min(pred)
max(pred)
min(y)
max(y)
fit$R2
library(testthat)
devtools::test()
coef
usethis::use_r("coef.lasso.R")
usethis::use_r("coef.LAR.R")
usethis::use_r("coef.ridge.R")
devtools::test()
devtools::test()
devtools::load_all()
devtools::test()
devtools::test()
devtools::test()
devtools::load_all()
devtools::test()
x
y
y
x
c
x
x1
x2
y <- 1:3
regmodel(y ~ x, model = "ridge")
regmodel(y ~ x, model = "ridge", lambda = 2)
regmodel(y ~ x, model = "ridge", lambda = 1)
regmodel(y ~ x, model = "ridge", lambda = c(2,1))
devtools::test()
devtools::test()
devtools::test()
rm(list = ls())
devtools::load_all()
X <- matrix(1:100, nrow = 20)
y <- 1:10
data <- data.frame(X, y)
formula <- as.formula(y ~ .)
X
X <- matrix(1:100, nrow = 20);colnames(X) <- paste("X",1:ncol(X))
X
X <- matrix(1:100, nrow = 20);colnames(X) <- paste("X",1:ncol(X), collapse = "")
X <- matrix(1:100, nrow = 20);colnames(X) <- paste("X",1:ncol(X), collapse = "")
X <- matrix(1:100, nrow = 20);colnames(X) <- paste("X",1:ncol(X), sep = "")
X
rm(list = ls())
devtools::load_all()
devtools::test()
X <- matrix(1:100, nrow = 20);colnames(X) <- paste("X",1:ncol(X), sep = "")
y <- 1:10
data <- data.frame(X, y)
formula <- as.formula(y ~ .)
result <- regmodel(formula = formula, data = data, model = "forward",
n_predictors = 1, verbose = F)
result
result$predictors
X <- matrix(1:100, nrow = 20)
y <- 1:10
data <- data.frame(X, y)
formula <- as.formula(y ~ .)
result <- regmodel(formula = formula, data = data, model = "forward",
n_predictors = 1, verbose = F)
result
result$model
devtools::test()
result <- regmodel(formula = formula, data = data, model = "backward",
n_predictors = 1, verbose = F)
X <- matrix(1:100, nrow = 20)
y <- 1:10
data <- data.frame(X, y)
formula <- as.formula(y ~ .)
test_that("forward selection input checks work", {
expect_error(regmodel(formula = formula, data = data, model = "forward",
n_predictors = -1, verbose = F))
expect_error(regmodel(formula = formula, data = data, model = "forward",
n_predictors = 0, verbose = F))
expect_no_error(regmodel(formula = formula, data = data, model = "forward",
n_predictors = 1, verbose = F))
})
test_that("backward selection input checks work", {
expect_error(regmodel(formula = formula, data = data, model = "backward",
n_predictors = -1, verbose = F))
expect_error(regmodel(formula = formula, data = data, model = "backward",
n_predictors = 0, verbose = F))
expect_error(regmodel(formula = formula, data = data.frame(x1=1, x2=1, y=1),
model = "backward", n_predictors = 1, verbose = F))
expect_no_error(regmodel(formula = formula, data = data, model = "backward",
n_predictors = 1, verbose = F))
})
test_that("forward selection output is correct", {
result <- regmodel(formula = formula, data = data, model = "forward",
n_predictors = 1, verbose = F)
expect_true(round(result$error, 6) == 6.203008)
expect_true(result$predictors == "X1")
expect_true(result$direction == "forward")
})
devtools::test()
devtools::test()
X
devtools::test()
test()
